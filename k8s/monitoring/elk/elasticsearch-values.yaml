# Production Elasticsearch configuration for MITA Financial Services
# High availability setup with financial compliance logging requirements

# Cluster configuration for high availability
clusterName: "mita-financial-logs"
nodeGroup: "master"

# Replica configuration for HA
replicas: 3
minimumMasterNodes: 2

# Elasticsearch version
imageTag: "8.11.0"

# Security configuration
createCert: true
protocol: https
httpPort: 9200
transportPort: 9300

# Resource allocation for financial logging workload
resources:
  requests:
    cpu: "1000m"
    memory: "4Gi"
  limits:
    cpu: "2000m"
    memory: "8Gi"

# JVM heap settings (50% of memory limit)
esJavaOpts: "-Xmx4g -Xms4g"

# Persistent volume configuration
persistence:
  enabled: true
  size: 500Gi
  storageClass: "fast-ssd"
  accessModes:
    - ReadWriteOnce

# Volume claim template for StatefulSet
volumeClaimTemplate:
  metadata:
    name: elasticsearch-master
  spec:
    accessModes: [ "ReadWriteOnce" ]
    storageClassName: "fast-ssd"
    resources:
      requests:
        storage: 500Gi

# Pod disruption budget
maxUnavailable: 1

# Security context
securityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000

# Pod security context
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000

# Service configuration
service:
  enabled: true
  type: ClusterIP
  port: 9200
  nodePort: ""
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9200"
    prometheus.io/path: "/_prometheus/metrics"

# Ingress configuration for management access
ingress:
  enabled: true
  className: "nginx"
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    nginx.ingress.kubernetes.io/auth-type: basic
    nginx.ingress.kubernetes.io/auth-secret: elasticsearch-basic-auth
    nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  hosts:
    - host: elasticsearch.mita.finance
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: elasticsearch-tls-cert
      hosts:
        - elasticsearch.mita.finance

# Elasticsearch configuration
esConfig:
  elasticsearch.yml: |
    # Network configuration
    network.host: 0.0.0.0
    network.publish_host: _local_
    
    # Cluster configuration
    cluster.name: mita-financial-logs
    node.name: ${HOSTNAME}
    node.master: true
    node.data: true
    node.ingest: true
    
    # Discovery configuration for Kubernetes
    discovery.seed_hosts: elasticsearch-master-headless
    cluster.initial_master_nodes: elasticsearch-master-0,elasticsearch-master-1,elasticsearch-master-2
    
    # Security configuration
    xpack.security.enabled: true
    xpack.security.transport.ssl.enabled: true
    xpack.security.transport.ssl.verification_mode: certificate
    xpack.security.transport.ssl.keystore.path: /usr/share/elasticsearch/config/certs/elastic-certificates.p12
    xpack.security.transport.ssl.truststore.path: /usr/share/elasticsearch/config/certs/elastic-certificates.p12
    xpack.security.http.ssl.enabled: true
    xpack.security.http.ssl.keystore.path: /usr/share/elasticsearch/config/certs/elastic-certificates.p12
    
    # Monitoring and metrics
    xpack.monitoring.collection.enabled: true
    xpack.monitoring.exporters:
      prometheus:
        type: http
        host: ["prometheus-operated:9090"]
    
    # Index lifecycle management for compliance
    xpack.ilm.enabled: true
    
    # Audit logging for financial compliance
    xpack.security.audit.enabled: true
    xpack.security.audit.logfile.events.emit_request_body: true
    xpack.security.audit.logfile.events.include:
      - access_granted
      - access_denied
      - anonymous_access_denied
      - authentication_failed
      - connection_granted
      - connection_denied
      - tampered_request
      - run_as_granted
      - run_as_denied
      - security_config_change
    
    # Performance settings for financial data
    indices.memory.index_buffer_size: 30%
    bootstrap.memory_lock: true
    
    # Thread pool settings
    thread_pool.write.queue_size: 1000
    thread_pool.search.queue_size: 1000
    
    # Financial compliance retention policy
    action.destructive_requires_name: true
    cluster.routing.allocation.disk.threshold.enabled: true
    cluster.routing.allocation.disk.watermark.low: 85%
    cluster.routing.allocation.disk.watermark.high: 90%
    cluster.routing.allocation.disk.watermark.flood_stage: 95%

# Environment variables
extraEnvs:
  - name: ELASTIC_PASSWORD
    valueFrom:
      secretKeyRef:
        name: elasticsearch-master-credentials
        key: password
  - name: ELASTIC_USERNAME
    valueFrom:
      secretKeyRef:
        name: elasticsearch-master-credentials
        key: username

# Secret management
secretMounts: []

# Node affinity and anti-affinity
nodeAffinity:
  requiredDuringSchedulingIgnoredDuringExecution:
    nodeSelectorTerms:
      - matchExpressions:
        - key: node.kubernetes.io/instance-type
          operator: NotIn
          values: ["t3.nano", "t3.micro", "t3.small"]

# Pod anti-affinity to distribute across nodes
podAntiAffinity:
  requiredDuringSchedulingIgnoredDuringExecution:
    - labelSelector:
        matchExpressions:
          - key: app
            operator: In
            values: ["elasticsearch-master"]
      topologyKey: kubernetes.io/hostname

# Tolerations for dedicated logging nodes
tolerations:
  - key: "logging"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"

# Lifecycle hooks
lifecycle:
  preStop:
    exec:
      command:
        - bash
        - -c
        - |
          if [[ $(curl -s -o /dev/null -w '%{http_code}' http://localhost:9200/_cluster/health?timeout=10s) == "200" ]]; then
            curl -XPOST 'localhost:9200/_cluster/nodes/_local/_shutdown?delay=10s&timeout=120s'
            sleep 15
          fi

# Readiness probe
readinessProbe:
  failureThreshold: 3
  initialDelaySeconds: 10
  periodSeconds: 10
  successThreshold: 3
  timeoutSeconds: 5
  exec:
    command:
      - bash
      - -c
      - |
        #!/usr/bin/env bash -e
        # If the node is starting up wait for the cluster to be ready (request params: "wait_for_status=yellow&timeout=1s" )
        # Once it has started only check that the node itself is responding
        START_FILE=/tmp/.es_start_file

        # Disable nss cache to avoid filling dentry cache when calling curl
        # This is required with Elasticsearch Docker using nss < 3.52
        export NSS_SDB_USE_CACHE=no

        http () {
          local path="${1}"
          local args="${2}"
          set -- -XGET -s

          if [ "$args" != "" ]; then
            set -- "$@" $args
          fi

          if [ -n "${ELASTIC_USERNAME}" ] && [ -n "${ELASTIC_PASSWORD}" ]; then
            set -- "$@" -u "${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}"
          fi

          curl --output /dev/null -k "$@" "https://127.0.0.1:9200${path}"
        }

        if [ -f "${START_FILE}" ]; then
          echo 'Elasticsearch is already running, lets check the node is healthy'
          HTTP_CODE=$(http "/" "-w %{http_code}")
          RC=$?
          if [[ ${RC} -ne 0 ]]; then
            echo "curl --output /dev/null -k -XGET -s -w '%{http_code}' \${BASIC_AUTH} https://127.0.0.1:9200/ failed with RC ${RC}"
            exit ${RC}
          fi
          # ready if HTTP code 200, 503 is tolerable if ES version is 6.x
          if [[ ${HTTP_CODE} == "200" ]]; then
            touch ${START_FILE}
            exit 0
          elif [[ ${HTTP_CODE} == "503" && "8.11.0" =~ "^6." ]]; then
            touch ${START_FILE}
            exit 0
          else
            echo "curl --output /dev/null -k -XGET -s -w '%{http_code}' \${BASIC_AUTH} https://127.0.0.1:9200/ failed with HTTP code ${HTTP_CODE}"
            exit 1
          fi

        else
          echo 'Waiting for elasticsearch cluster to become ready (request params: "wait_for_status=yellow&timeout=1s" )'
          if http "/_cluster/health?wait_for_status=yellow&timeout=1s" "--fail" ; then
            touch ${START_FILE}
            exit 0
          else
            echo 'Cluster is not yet ready (request params: "wait_for_status=yellow&timeout=1s" )'
            exit 1
          fi
        fi

# Labels for monitoring
labels:
  app.kubernetes.io/name: elasticsearch
  app.kubernetes.io/component: elasticsearch
  environment: production
  compliance: "SOX,PCI-DSS"
  business-function: "financial-logging"

# Network policy
networkPolicy:
  enabled: true
  http:
    enabled: true
  transport:
    enabled: true
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: ingress-nginx
      ports:
        - port: 9200
          protocol: TCP
    - from:
        - namespaceSelector:
            matchLabels:
              name: monitoring
      ports:
        - port: 9200
          protocol: TCP
    - from:
        - podSelector:
            matchLabels:
              app: logstash
      ports:
        - port: 9200
          protocol: TCP
  egress:
    - to: []
      ports:
        - port: 53
          protocol: UDP
        - port: 53
          protocol: TCP
        - port: 443
          protocol: TCP