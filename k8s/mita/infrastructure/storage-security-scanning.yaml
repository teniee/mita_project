# Storage Security Scanning and Vulnerability Management for MITA Financial Application
# This configuration implements comprehensive security scanning, vulnerability assessment,
# and compliance monitoring for all storage infrastructure components

apiVersion: v1
kind: ConfigMap
metadata:
  name: storage-security-config
  namespace: mita-production
  labels:
    app.kubernetes.io/name: mita
    app.kubernetes.io/component: security-scanning
    app.kubernetes.io/part-of: mita-finance
data:
  # Terraform configuration for AWS Security Hub and GuardDuty integration
  terraform-security-config.tf: |
    # Storage Security Scanning Infrastructure for MITA Finance
    
    # Data sources
    data "aws_caller_identity" "current" {}
    data "aws_region" "current" {}
    
    # Enable AWS Security Hub
    resource "aws_securityhub_account" "mita_security_hub" {
      enable_default_standards = true
    }
    
    # Enable GuardDuty
    resource "aws_guardduty_detector" "mita_guardduty" {
      enable = true
      
      datasources {
        s3_logs {
          enable = true
        }
        kubernetes {
          audit_logs {
            enable = true
          }
        }
        malware_protection {
          scan_ec2_instance_with_findings {
            ebs_volumes {
              enable = true
            }
          }
        }
      }
      
      tags = {
        Name        = "mita-guardduty-detector"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "security-monitoring"
      }
    }
    
    # GuardDuty S3 Protection
    resource "aws_guardduty_detector_feature" "s3_protection" {
      detector_id = aws_guardduty_detector.mita_guardduty.id
      name        = "S3_DATA_EVENTS"
      status      = "ENABLED"
      
      additional_configuration {
        name   = "EKS_ADDON_MANAGEMENT"
        status = "ENABLED"
      }
    }
    
    # Enable AWS Config for compliance monitoring
    resource "aws_config_configuration_recorder" "mita_config" {
      name     = "mita-config-recorder"
      role_arn = aws_iam_role.mita_config.arn
      
      recording_group {
        all_supported                 = true
        include_global_resource_types = true
      }
      
      depends_on = [aws_config_delivery_channel.mita_config]
    }
    
    resource "aws_config_delivery_channel" "mita_config" {
      name           = "mita-config-delivery-channel"
      s3_bucket_name = aws_s3_bucket.mita_config_bucket.bucket
      s3_key_prefix  = "config"
      
      snapshot_delivery_properties {
        delivery_frequency = "TwentyFour_Hours"
      }
    }
    
    # S3 bucket for AWS Config
    resource "aws_s3_bucket" "mita_config_bucket" {
      bucket        = "mita-finance-config-${random_string.config_suffix.result}"
      force_destroy = false
      
      tags = {
        Name        = "mita-config-bucket"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "compliance-monitoring"
      }
    }
    
    resource "random_string" "config_suffix" {
      length  = 8
      special = false
      upper   = false
    }
    
    # Config bucket encryption
    resource "aws_s3_bucket_server_side_encryption_configuration" "mita_config_bucket" {
      bucket = aws_s3_bucket.mita_config_bucket.id
      
      rule {
        apply_server_side_encryption_by_default {
          kms_master_key_id = aws_kms_key.mita_config_encryption.arn
          sse_algorithm     = "aws:kms"
        }
        bucket_key_enabled = true
      }
    }
    
    # KMS key for Config encryption
    resource "aws_kms_key" "mita_config_encryption" {
      description             = "KMS key for MITA Config encryption"
      deletion_window_in_days = 7
      enable_key_rotation     = true
      
      policy = jsonencode({
        Version = "2012-10-17"
        Statement = [
          {
            Sid    = "EnableIAMUserPermissions"
            Effect = "Allow"
            Principal = {
              AWS = "arn:aws:iam::${data.aws_caller_identity.current.account_id}:root"
            }
            Action   = "kms:*"
            Resource = "*"
          },
          {
            Sid    = "AllowConfigService"
            Effect = "Allow"
            Principal = {
              Service = "config.amazonaws.com"
            }
            Action = [
              "kms:Decrypt",
              "kms:DescribeKey",
              "kms:Encrypt",
              "kms:GenerateDataKey*",
              "kms:ReEncrypt*"
            ]
            Resource = "*"
          }
        ]
      })
      
      tags = {
        Name        = "mita-config-encryption-key"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "compliance-monitoring"
      }
    }
    
    # Config bucket policy
    resource "aws_s3_bucket_policy" "mita_config_bucket" {
      bucket = aws_s3_bucket.mita_config_bucket.id
      
      policy = jsonencode({
        Version = "2012-10-17"
        Statement = [
          {
            Sid    = "AWSConfigBucketPermissionsCheck"
            Effect = "Allow"
            Principal = {
              Service = "config.amazonaws.com"
            }
            Action   = "s3:GetBucketAcl"
            Resource = aws_s3_bucket.mita_config_bucket.arn
            Condition = {
              StringEquals = {
                "AWS:SourceAccount" = data.aws_caller_identity.current.account_id
              }
            }
          },
          {
            Sid    = "AWSConfigBucketExistenceCheck"
            Effect = "Allow"
            Principal = {
              Service = "config.amazonaws.com"
            }
            Action   = "s3:ListBucket"
            Resource = aws_s3_bucket.mita_config_bucket.arn
            Condition = {
              StringEquals = {
                "AWS:SourceAccount" = data.aws_caller_identity.current.account_id
              }
            }
          },
          {
            Sid    = "AWSConfigBucketDelivery"
            Effect = "Allow"
            Principal = {
              Service = "config.amazonaws.com"
            }
            Action   = "s3:PutObject"
            Resource = "${aws_s3_bucket.mita_config_bucket.arn}/*"
            Condition = {
              StringEquals = {
                "s3:x-amz-acl" = "bucket-owner-full-control"
                "AWS:SourceAccount" = data.aws_caller_identity.current.account_id
              }
            }
          }
        ]
      })
    }
    
    # IAM role for AWS Config
    resource "aws_iam_role" "mita_config" {
      name = "mita-config-role"
      
      assume_role_policy = jsonencode({
        Version = "2012-10-17"
        Statement = [
          {
            Action = "sts:AssumeRole"
            Effect = "Allow"
            Principal = {
              Service = "config.amazonaws.com"
            }
          }
        ]
      })
      
      tags = {
        Name        = "mita-config-role"
        Environment = "production"
        Application = "mita-finance"
      }
    }
    
    resource "aws_iam_role_policy_attachment" "mita_config" {
      role       = aws_iam_role.mita_config.name
      policy_arn = "arn:aws:iam::aws:policy/service-role/ConfigRole"
    }
    
    # AWS Config Rules for storage security compliance
    resource "aws_config_config_rule" "s3_bucket_public_access_prohibited" {
      name = "s3-bucket-public-access-prohibited"
      
      source {
        owner             = "AWS"
        source_identifier = "S3_BUCKET_PUBLIC_ACCESS_PROHIBITED"
      }
      
      depends_on = [aws_config_configuration_recorder.mita_config]
    }
    
    resource "aws_config_config_rule" "s3_bucket_ssl_requests_only" {
      name = "s3-bucket-ssl-requests-only"
      
      source {
        owner             = "AWS"
        source_identifier = "S3_BUCKET_SSL_REQUESTS_ONLY"
      }
      
      depends_on = [aws_config_configuration_recorder.mita_config]
    }
    
    resource "aws_config_config_rule" "s3_bucket_server_side_encryption_enabled" {
      name = "s3-bucket-server-side-encryption-enabled"
      
      source {
        owner             = "AWS"
        source_identifier = "S3_BUCKET_SERVER_SIDE_ENCRYPTION_ENABLED"
      }
      
      depends_on = [aws_config_configuration_recorder.mita_config]
    }
    
    resource "aws_config_config_rule" "rds_encrypted_at_rest" {
      name = "rds-storage-encrypted"
      
      source {
        owner             = "AWS"
        source_identifier = "RDS_STORAGE_ENCRYPTED"
      }
      
      depends_on = [aws_config_configuration_recorder.mita_config]
    }
    
    resource "aws_config_config_rule" "elasticache_redis_cluster_automatic_backup_check" {
      name = "elasticache-redis-cluster-automatic-backup-check"
      
      source {
        owner             = "AWS"
        source_identifier = "ELASTICACHE_REDIS_CLUSTER_AUTOMATIC_BACKUP_CHECK"
      }
      
      depends_on = [aws_config_configuration_recorder.mita_config]
    }
    
    # Lambda function for custom security scanning
    resource "aws_lambda_function" "mita_security_scanner" {
      filename         = "mita_security_scanner.zip"
      function_name    = "mita-security-scanner"
      role            = aws_iam_role.mita_security_scanner.arn
      handler         = "index.handler"
      runtime         = "python3.11"
      timeout         = 900  # 15 minutes
      memory_size     = 1024
      
      environment {
        variables = {
          SECURITY_HUB_REGION       = data.aws_region.current.name
          DOCUMENTS_BUCKET_NAME     = var.documents_bucket_name
          BACKUP_BUCKET_NAME        = var.backup_bucket_name
          RDS_INSTANCE_IDENTIFIER   = var.rds_instance_identifier
          REDIS_CLUSTER_ID          = var.redis_cluster_id
          SNS_TOPIC_ARN            = aws_sns_topic.mita_security_alerts.arn
          COMPLIANCE_STANDARDS      = "PCI-DSS,SOX,FFIEC"
        }
      }
      
      tags = {
        Name        = "mita-security-scanner"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "security-scanning"
      }
    }
    
    # IAM role for security scanner Lambda
    resource "aws_iam_role" "mita_security_scanner" {
      name = "mita-security-scanner-role"
      
      assume_role_policy = jsonencode({
        Version = "2012-10-17"
        Statement = [
          {
            Action = "sts:AssumeRole"
            Effect = "Allow"
            Principal = {
              Service = "lambda.amazonaws.com"
            }
          }
        ]
      })
      
      tags = {
        Name        = "mita-security-scanner-role"
        Environment = "production"
        Application = "mita-finance"
      }
    }
    
    # IAM policy for security scanner
    resource "aws_iam_policy" "mita_security_scanner" {
      name        = "mita-security-scanner-policy"
      description = "Policy for MITA security scanner Lambda"
      
      policy = jsonencode({
        Version = "2012-10-17"
        Statement = [
          {
            Effect = "Allow"
            Action = [
              "logs:CreateLogGroup",
              "logs:CreateLogStream",
              "logs:PutLogEvents"
            ]
            Resource = "arn:aws:logs:*:*:*"
          },
          {
            Effect = "Allow"
            Action = [
              "s3:GetBucketAcl",
              "s3:GetBucketPolicy",
              "s3:GetBucketPolicyStatus",
              "s3:GetBucketPublicAccessBlock",
              "s3:GetBucketEncryption",
              "s3:GetBucketVersioning",
              "s3:GetBucketLifecycleConfiguration",
              "s3:GetBucketLogging",
              "s3:ListBucket"
            ]
            Resource = [
              var.documents_bucket_arn,
              var.backup_bucket_arn,
              aws_s3_bucket.mita_config_bucket.arn
            ]
          },
          {
            Effect = "Allow"
            Action = [
              "rds:DescribeDBInstances",
              "rds:DescribeDBClusters",
              "rds:DescribeDBSnapshots",
              "rds:DescribeDBParameterGroups",
              "rds:DescribeDBSubnetGroups"
            ]
            Resource = "*"
            Condition = {
              StringEquals = {
                "aws:ResourceTag/Application" = "mita-finance"
              }
            }
          },
          {
            Effect = "Allow"
            Action = [
              "elasticache:DescribeReplicationGroups",
              "elasticache:DescribeCacheClusters",
              "elasticache:DescribeSnapshots",
              "elasticache:DescribeCacheParameterGroups",
              "elasticache:DescribeCacheSubnetGroups"
            ]
            Resource = "*"
            Condition = {
              StringEquals = {
                "aws:ResourceTag/Application" = "mita-finance"
              }
            }
          },
          {
            Effect = "Allow"
            Action = [
              "kms:DescribeKey",
              "kms:GetKeyPolicy",
              "kms:GetKeyRotationStatus",
              "kms:ListAliases",
              "kms:ListKeys"
            ]
            Resource = "*"
          },
          {
            Effect = "Allow"
            Action = [
              "securityhub:BatchImportFindings",
              "securityhub:CreateInsight",
              "securityhub:GetFindings"
            ]
            Resource = "*"
          },
          {
            Effect = "Allow"
            Action = [
              "sns:Publish"
            ]
            Resource = aws_sns_topic.mita_security_alerts.arn
          },
          {
            Effect = "Allow"
            Action = [
              "cloudwatch:PutMetricData"
            ]
            Resource = "*"
          }
        ]
      })
      
      tags = {
        Name        = "mita-security-scanner-policy"
        Environment = "production"
        Application = "mita-finance"
      }
    }
    
    resource "aws_iam_role_policy_attachment" "mita_security_scanner" {
      role       = aws_iam_role.mita_security_scanner.name
      policy_arn = aws_iam_policy.mita_security_scanner.arn
    }
    
    # SNS topic for security alerts
    resource "aws_sns_topic" "mita_security_alerts" {
      name         = "mita-security-alerts"
      display_name = "MITA Security Alerts"
      kms_master_key_id = aws_kms_key.mita_config_encryption.arn
      
      tags = {
        Name        = "mita-security-alerts"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "security-alerting"
      }
    }
    
    # EventBridge rule for daily security scanning
    resource "aws_cloudwatch_event_rule" "mita_daily_security_scan" {
      name                = "mita-daily-security-scan"
      description         = "Trigger daily security scanning"
      schedule_expression = "cron(0 6 * * ? *)"  # Daily at 6 AM UTC
      
      tags = {
        Name        = "mita-daily-security-scan"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "security-scanning"
      }
    }
    
    resource "aws_cloudwatch_event_target" "mita_daily_security_scan" {
      rule      = aws_cloudwatch_event_rule.mita_daily_security_scan.name
      target_id = "TriggerSecurityScan"
      arn       = aws_lambda_function.mita_security_scanner.arn
      
      input = jsonencode({
        scan_type = "comprehensive"
        include_compliance_check = true
      })
    }
    
    resource "aws_lambda_permission" "allow_eventbridge_security_scan" {
      statement_id  = "AllowExecutionFromEventBridge"
      action        = "lambda:InvokeFunction"
      function_name = aws_lambda_function.mita_security_scanner.function_name
      principal     = "events.amazonaws.com"
      source_arn    = aws_cloudwatch_event_rule.mita_daily_security_scan.arn
    }
    
    # Inspector V2 for vulnerability assessment
    resource "aws_inspector2_enabler" "mita_inspector" {
      account_ids    = [data.aws_caller_identity.current.account_id]
      resource_types = ["ECR", "EC2"]
    }
    
    # CloudWatch dashboard for security monitoring
    resource "aws_cloudwatch_dashboard" "mita_security_monitoring" {
      dashboard_name = "MITA-Security-Monitoring"
      
      dashboard_body = jsonencode({
        widgets = [
          {
            type   = "metric"
            x      = 0
            y      = 0
            width  = 12
            height = 6
            
            properties = {
              metrics = [
                ["MITA/Security", "VulnerabilitiesFound", "ScanType", "Storage"],
                [".", "ComplianceViolations", ".", "."],
                [".", "SecurityFindings", ".", "."]
              ]
              view    = "timeSeries"
              stacked = false
              region  = data.aws_region.current.name
              title   = "Security Metrics"
              period  = 86400
            }
          },
          {
            type   = "log"
            x      = 12
            y      = 0
            width  = 12
            height = 6
            
            properties = {
              query   = "SOURCE '/aws/lambda/mita-security-scanner' | fields @timestamp, @message | filter @message like /CRITICAL/ or @message like /HIGH/ | sort @timestamp desc | limit 50"
              region  = data.aws_region.current.name
              title   = "Critical Security Findings"
              view    = "table"
            }
          },
          {
            type   = "metric"
            x      = 0
            y      = 6
            width  = 24
            height = 6
            
            properties = {
              metrics = [
                ["AWS/GuardDuty", "FindingCount", "DetectorId", aws_guardduty_detector.mita_guardduty.id]
              ]
              view   = "timeSeries"
              region = data.aws_region.current.name
              title  = "GuardDuty Findings"
              period = 3600
            }
          }
        ]
      })
    }
    
    # Variables
    variable "documents_bucket_name" {
      description = "Name of the documents S3 bucket"
      type        = string
    }
    
    variable "documents_bucket_arn" {
      description = "ARN of the documents S3 bucket"
      type        = string
    }
    
    variable "backup_bucket_name" {
      description = "Name of the backup S3 bucket"
      type        = string
    }
    
    variable "backup_bucket_arn" {
      description = "ARN of the backup S3 bucket"
      type        = string
    }
    
    variable "rds_instance_identifier" {
      description = "Identifier of the RDS instance"
      type        = string
    }
    
    variable "redis_cluster_id" {
      description = "ID of the Redis cluster"
      type        = string
    }
    
    # Outputs
    output "security_hub_arn" {
      description = "ARN of the Security Hub account"
      value       = aws_securityhub_account.mita_security_hub.arn
    }
    
    output "guardduty_detector_id" {
      description = "ID of the GuardDuty detector"
      value       = aws_guardduty_detector.mita_guardduty.id
    }
    
    output "config_recorder_name" {
      description = "Name of the Config recorder"
      value       = aws_config_configuration_recorder.mita_config.name
    }
    
    output "security_scanner_function_arn" {
      description = "ARN of the security scanner Lambda function"
      value       = aws_lambda_function.mita_security_scanner.arn
    }
    
    output "security_alerts_topic_arn" {
      description = "ARN of the security alerts SNS topic"
      value       = aws_sns_topic.mita_security_alerts.arn
    }

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: security-scanner-lambda
  namespace: mita-production
  labels:
    app.kubernetes.io/name: mita
    app.kubernetes.io/component: security-scanning
    app.kubernetes.io/part-of: mita-finance
data:
  security_scanner.py: |
    import json
    import boto3
    import os
    import logging
    from datetime import datetime, timedelta
    from typing import Dict, Any, List
    import hashlib
    
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    s3 = boto3.client('s3')
    rds = boto3.client('rds')
    elasticache = boto3.client('elasticache')
    kms = boto3.client('kms')
    securityhub = boto3.client('securityhub')
    sns = boto3.client('sns')
    cloudwatch = boto3.client('cloudwatch')
    
    def handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
        """Lambda function for comprehensive storage security scanning."""
        try:
            scan_type = event.get('scan_type', 'basic')
            include_compliance = event.get('include_compliance_check', True)
            
            scan_start = datetime.utcnow()
            logger.info(f"Starting {scan_type} security scan")
            
            scan_results = {
                'scan_id': generate_scan_id(),
                'scan_type': scan_type,
                'timestamp': scan_start.isoformat(),
                's3_findings': scan_s3_security(),
                'rds_findings': scan_rds_security(),
                'redis_findings': scan_redis_security(),
                'kms_findings': scan_kms_security(),
                'compliance_findings': scan_compliance() if include_compliance else {}
            }
            
            # Calculate risk scores
            scan_results['risk_assessment'] = calculate_risk_score(scan_results)
            
            # Send findings to Security Hub
            send_to_security_hub(scan_results)
            
            # Record metrics
            record_security_metrics(scan_results)
            
            # Send alerts for high-risk findings
            if scan_results['risk_assessment']['overall_risk'] >= 7:
                send_security_alert(scan_results)
            
            scan_end = datetime.utcnow()
            scan_duration = (scan_end - scan_start).total_seconds()
            
            logger.info(f"Security scan completed in {scan_duration:.2f} seconds")
            
            return {
                'statusCode': 200,
                'body': json.dumps({
                    'scan_id': scan_results['scan_id'],
                    'overall_risk': scan_results['risk_assessment']['overall_risk'],
                    'critical_findings': scan_results['risk_assessment']['critical_count'],
                    'high_findings': scan_results['risk_assessment']['high_count'],
                    'scan_duration_seconds': scan_duration
                })
            }
            
        except Exception as e:
            error_msg = f"Security scan failed: {str(e)}"
            logger.error(error_msg)
            
            # Record failure metrics
            cloudwatch.put_metric_data(
                Namespace='MITA/Security',
                MetricData=[
                    {
                        'MetricName': 'ScanFailure',
                        'Value': 1,
                        'Unit': 'Count'
                    }
                ]
            )
            
            return {
                'statusCode': 500,
                'body': json.dumps({'error': error_msg})
            }
    
    def generate_scan_id() -> str:
        """Generate unique scan ID."""
        timestamp = datetime.utcnow().strftime('%Y%m%d%H%M%S')
        hash_input = f"mita-security-{timestamp}".encode()
        hash_suffix = hashlib.md5(hash_input).hexdigest()[:8]
        return f"scan-{timestamp}-{hash_suffix}"
    
    def scan_s3_security() -> List[Dict[str, Any]]:
        """Scan S3 buckets for security issues."""
        findings = []
        buckets_to_scan = [
            os.environ['DOCUMENTS_BUCKET_NAME'],
            os.environ['BACKUP_BUCKET_NAME']
        ]
        
        for bucket_name in buckets_to_scan:
            try:
                logger.info(f"Scanning S3 bucket: {bucket_name}")
                
                # Check public access block
                try:
                    public_access = s3.get_public_access_block(Bucket=bucket_name)
                    pab = public_access['PublicAccessBlockConfiguration']
                    
                    if not all([
                        pab['BlockPublicAcls'],
                        pab['IgnorePublicAcls'],
                        pab['BlockPublicPolicy'],
                        pab['RestrictPublicBuckets']
                    ]):
                        findings.append({
                            'type': 'S3_PUBLIC_ACCESS_NOT_BLOCKED',
                            'severity': 'CRITICAL',
                            'resource': bucket_name,
                            'description': 'S3 bucket public access is not fully blocked',
                            'remediation': 'Enable all public access block settings'
                        })
                except Exception as e:
                    findings.append({
                        'type': 'S3_PUBLIC_ACCESS_CHECK_FAILED',
                        'severity': 'HIGH',
                        'resource': bucket_name,
                        'description': f'Failed to check public access block: {str(e)}',
                        'remediation': 'Verify bucket permissions and access'
                    })
                
                # Check encryption
                try:
                    encryption = s3.get_bucket_encryption(Bucket=bucket_name)
                    rules = encryption['ServerSideEncryptionConfiguration']['Rules']
                    
                    kms_encrypted = any(
                        rule['ApplyServerSideEncryptionByDefault']['SSEAlgorithm'] == 'aws:kms'
                        for rule in rules
                    )
                    
                    if not kms_encrypted:
                        findings.append({
                            'type': 'S3_KMS_ENCRYPTION_MISSING',
                            'severity': 'HIGH',
                            'resource': bucket_name,
                            'description': 'S3 bucket is not using KMS encryption',
                            'remediation': 'Enable KMS encryption for the bucket'
                        })
                        
                except Exception as e:
                    findings.append({
                        'type': 'S3_ENCRYPTION_CHECK_FAILED',
                        'severity': 'MEDIUM',
                        'resource': bucket_name,
                        'description': f'Failed to check encryption: {str(e)}',
                        'remediation': 'Verify bucket encryption configuration'
                    })
                
                # Check versioning
                try:
                    versioning = s3.get_bucket_versioning(Bucket=bucket_name)
                    if versioning.get('Status') != 'Enabled':
                        findings.append({
                            'type': 'S3_VERSIONING_DISABLED',
                            'severity': 'MEDIUM',
                            'resource': bucket_name,
                            'description': 'S3 bucket versioning is not enabled',
                            'remediation': 'Enable versioning for data protection'
                        })
                except Exception as e:
                    logger.warning(f"Failed to check versioning for {bucket_name}: {e}")
                
                # Check logging
                try:
                    logging_config = s3.get_bucket_logging(Bucket=bucket_name)
                    if 'LoggingEnabled' not in logging_config:
                        findings.append({
                            'type': 'S3_ACCESS_LOGGING_DISABLED',
                            'severity': 'MEDIUM',
                            'resource': bucket_name,
                            'description': 'S3 bucket access logging is not enabled',
                            'remediation': 'Enable access logging for audit trail'
                        })
                except Exception as e:
                    logger.warning(f"Failed to check logging for {bucket_name}: {e}")
                
                # Check bucket policy for HTTPS enforcement
                try:
                    bucket_policy = s3.get_bucket_policy(Bucket=bucket_name)
                    policy_doc = json.loads(bucket_policy['Policy'])
                    
                    https_enforced = any(
                        stmt.get('Condition', {}).get('Bool', {}).get('aws:SecureTransport') == 'false'
                        and stmt.get('Effect') == 'Deny'
                        for stmt in policy_doc.get('Statement', [])
                    )
                    
                    if not https_enforced:
                        findings.append({
                            'type': 'S3_HTTPS_NOT_ENFORCED',
                            'severity': 'HIGH',
                            'resource': bucket_name,
                            'description': 'S3 bucket does not enforce HTTPS',
                            'remediation': 'Add bucket policy to deny non-HTTPS requests'
                        })
                        
                except Exception as e:
                    findings.append({
                        'type': 'S3_HTTPS_CHECK_FAILED',
                        'severity': 'LOW',
                        'resource': bucket_name,
                        'description': f'Failed to check HTTPS enforcement: {str(e)}',
                        'remediation': 'Verify bucket policy configuration'
                    })
                    
            except Exception as e:
                logger.error(f"Failed to scan bucket {bucket_name}: {e}")
                findings.append({
                    'type': 'S3_SCAN_FAILED',
                    'severity': 'HIGH',
                    'resource': bucket_name,
                    'description': f'Failed to complete security scan: {str(e)}',
                    'remediation': 'Check bucket permissions and configuration'
                })
        
        return findings
    
    def scan_rds_security() -> List[Dict[str, Any]]:
        """Scan RDS instances for security issues."""
        findings = []
        
        try:
            instances = rds.describe_db_instances()['DBInstances']
            mita_instances = [
                db for db in instances
                if db['DBInstanceIdentifier'].startswith('mita-postgresql')
            ]
            
            for instance in mita_instances:
                instance_id = instance['DBInstanceIdentifier']
                logger.info(f"Scanning RDS instance: {instance_id}")
                
                # Check encryption at rest
                if not instance.get('StorageEncrypted', False):
                    findings.append({
                        'type': 'RDS_ENCRYPTION_AT_REST_DISABLED',
                        'severity': 'CRITICAL',
                        'resource': instance_id,
                        'description': 'RDS instance does not have encryption at rest enabled',
                        'remediation': 'Enable encryption at rest for the database'
                    })
                
                # Check public accessibility
                if instance.get('PubliclyAccessible', False):
                    findings.append({
                        'type': 'RDS_PUBLICLY_ACCESSIBLE',
                        'severity': 'CRITICAL',
                        'resource': instance_id,
                        'description': 'RDS instance is publicly accessible',
                        'remediation': 'Disable public accessibility'
                    })
                
                # Check backup retention
                backup_retention = instance.get('BackupRetentionPeriod', 0)
                if backup_retention < 7:
                    findings.append({
                        'type': 'RDS_INSUFFICIENT_BACKUP_RETENTION',
                        'severity': 'HIGH',
                        'resource': instance_id,
                        'description': f'RDS backup retention is only {backup_retention} days',
                        'remediation': 'Set backup retention to at least 7 days'
                    })
                
                # Check Multi-AZ
                if not instance.get('MultiAZ', False) and 'read-replica' not in instance_id:
                    findings.append({
                        'type': 'RDS_MULTI_AZ_DISABLED',
                        'severity': 'HIGH',
                        'resource': instance_id,
                        'description': 'RDS instance does not have Multi-AZ enabled',
                        'remediation': 'Enable Multi-AZ for high availability'
                    })
                
                # Check deletion protection
                if not instance.get('DeletionProtection', False):
                    findings.append({
                        'type': 'RDS_DELETION_PROTECTION_DISABLED',
                        'severity': 'MEDIUM',
                        'resource': instance_id,
                        'description': 'RDS instance does not have deletion protection enabled',
                        'remediation': 'Enable deletion protection'
                    })
                
                # Check monitoring
                if not instance.get('MonitoringInterval', 0) > 0:
                    findings.append({
                        'type': 'RDS_ENHANCED_MONITORING_DISABLED',
                        'severity': 'MEDIUM',
                        'resource': instance_id,
                        'description': 'RDS enhanced monitoring is not enabled',
                        'remediation': 'Enable enhanced monitoring'
                    })
                
        except Exception as e:
            logger.error(f"Failed to scan RDS instances: {e}")
            findings.append({
                'type': 'RDS_SCAN_FAILED',
                'severity': 'HIGH',
                'resource': 'RDS_INSTANCES',
                'description': f'Failed to complete RDS security scan: {str(e)}',
                'remediation': 'Check RDS permissions and configuration'
            })
        
        return findings
    
    def scan_redis_security() -> List[Dict[str, Any]]:
        """Scan Redis clusters for security issues."""
        findings = []
        
        try:
            clusters = elasticache.describe_replication_groups()['ReplicationGroups']
            mita_clusters = [
                cluster for cluster in clusters
                if cluster['ReplicationGroupId'].startswith('mita-redis')
            ]
            
            for cluster in mita_clusters:
                cluster_id = cluster['ReplicationGroupId']
                logger.info(f"Scanning Redis cluster: {cluster_id}")
                
                # Check encryption at rest
                if not cluster.get('AtRestEncryptionEnabled', False):
                    findings.append({
                        'type': 'REDIS_ENCRYPTION_AT_REST_DISABLED',
                        'severity': 'CRITICAL',
                        'resource': cluster_id,
                        'description': 'Redis cluster does not have encryption at rest enabled',
                        'remediation': 'Enable encryption at rest for the cluster'
                    })
                
                # Check encryption in transit
                if not cluster.get('TransitEncryptionEnabled', False):
                    findings.append({
                        'type': 'REDIS_ENCRYPTION_IN_TRANSIT_DISABLED',
                        'severity': 'HIGH',
                        'resource': cluster_id,
                        'description': 'Redis cluster does not have encryption in transit enabled',
                        'remediation': 'Enable encryption in transit'
                    })
                
                # Check auth token
                if not cluster.get('AuthTokenEnabled', False):
                    findings.append({
                        'type': 'REDIS_AUTH_TOKEN_DISABLED',
                        'severity': 'HIGH',
                        'resource': cluster_id,
                        'description': 'Redis cluster does not have auth token enabled',
                        'remediation': 'Enable auth token for authentication'
                    })
                
                # Check automatic failover
                if not cluster.get('AutomaticFailover') == 'enabled':
                    findings.append({
                        'type': 'REDIS_AUTOMATIC_FAILOVER_DISABLED',
                        'severity': 'MEDIUM',
                        'resource': cluster_id,
                        'description': 'Redis cluster does not have automatic failover enabled',
                        'remediation': 'Enable automatic failover for high availability'
                    })
                
                # Check Multi-AZ
                if not cluster.get('MultiAZ') == 'enabled':
                    findings.append({
                        'type': 'REDIS_MULTI_AZ_DISABLED',
                        'severity': 'MEDIUM',
                        'resource': cluster_id,
                        'description': 'Redis cluster does not have Multi-AZ enabled',
                        'remediation': 'Enable Multi-AZ for high availability'
                    })
                
        except Exception as e:
            logger.error(f"Failed to scan Redis clusters: {e}")
            findings.append({
                'type': 'REDIS_SCAN_FAILED',
                'severity': 'HIGH',
                'resource': 'REDIS_CLUSTERS',
                'description': f'Failed to complete Redis security scan: {str(e)}',
                'remediation': 'Check Redis permissions and configuration'
            })
        
        return findings
    
    def scan_kms_security() -> List[Dict[str, Any]]:
        """Scan KMS keys for security issues."""
        findings = []
        
        try:
            keys = kms.list_keys()['Keys']
            
            for key in keys:
                key_id = key['KeyId']
                try:
                    key_details = kms.describe_key(KeyId=key_id)['KeyMetadata']
                    
                    # Skip AWS managed keys
                    if key_details.get('KeyManager') == 'AWS':
                        continue
                    
                    # Check if key is used by MITA (based on description or aliases)
                    key_description = key_details.get('Description', '').lower()
                    if 'mita' not in key_description:
                        continue
                    
                    logger.info(f"Scanning KMS key: {key_id}")
                    
                    # Check key rotation
                    rotation_status = kms.get_key_rotation_status(KeyId=key_id)
                    if not rotation_status.get('KeyRotationEnabled', False):
                        findings.append({
                            'type': 'KMS_KEY_ROTATION_DISABLED',
                            'severity': 'MEDIUM',
                            'resource': key_id,
                            'description': 'KMS key does not have automatic rotation enabled',
                            'remediation': 'Enable automatic key rotation'
                        })
                    
                    # Check key state
                    if key_details.get('KeyState') != 'Enabled':
                        findings.append({
                            'type': 'KMS_KEY_NOT_ENABLED',
                            'severity': 'HIGH',
                            'resource': key_id,
                            'description': f"KMS key state is {key_details.get('KeyState')}",
                            'remediation': 'Ensure KMS key is enabled'
                        })
                    
                    # Check key policy
                    try:
                        key_policy = kms.get_key_policy(KeyId=key_id, PolicyName='default')
                        policy_doc = json.loads(key_policy['Policy'])
                        
                        # Check for overly permissive policies
                        for statement in policy_doc.get('Statement', []):
                            if (statement.get('Effect') == 'Allow' and
                                statement.get('Principal') == '*' and
                                'kms:*' in statement.get('Action', [])):
                                
                                findings.append({
                                    'type': 'KMS_OVERLY_PERMISSIVE_POLICY',
                                    'severity': 'HIGH',
                                    'resource': key_id,
                                    'description': 'KMS key has overly permissive policy',
                                    'remediation': 'Restrict key policy to specific principals'
                                })
                                break
                                
                    except Exception as e:
                        logger.warning(f"Failed to check policy for key {key_id}: {e}")
                    
                except Exception as e:
                    logger.warning(f"Failed to check key {key_id}: {e}")
            
        except Exception as e:
            logger.error(f"Failed to scan KMS keys: {e}")
            findings.append({
                'type': 'KMS_SCAN_FAILED',
                'severity': 'HIGH',
                'resource': 'KMS_KEYS',
                'description': f'Failed to complete KMS security scan: {str(e)}',
                'remediation': 'Check KMS permissions and configuration'
            })
        
        return findings
    
    def scan_compliance() -> Dict[str, Any]:
        """Scan for compliance with financial regulations."""
        compliance_results = {
            'pci_dss': check_pci_dss_compliance(),
            'sox': check_sox_compliance(),
            'ffiec': check_ffiec_compliance()
        }
        
        return compliance_results
    
    def check_pci_dss_compliance() -> Dict[str, Any]:
        """Check PCI-DSS compliance requirements."""
        checks = {
            'data_encryption': True,  # Placeholder - would check actual encryption
            'access_controls': True,  # Placeholder - would check IAM policies
            'network_security': True,  # Placeholder - would check security groups
            'logging_monitoring': True,  # Placeholder - would check CloudTrail/CloudWatch
            'vulnerability_management': True  # Placeholder - would check patch levels
        }
        
        compliance_score = sum(checks.values()) / len(checks) * 100
        
        return {
            'compliant': compliance_score >= 90,
            'score': compliance_score,
            'checks': checks,
            'requirements_met': sum(checks.values()),
            'total_requirements': len(checks)
        }
    
    def check_sox_compliance() -> Dict[str, Any]:
        """Check SOX compliance requirements."""
        checks = {
            'data_integrity': True,  # Placeholder
            'access_logging': True,  # Placeholder
            'change_management': True,  # Placeholder
            'backup_retention': True,  # Placeholder
            'audit_trail': True  # Placeholder
        }
        
        compliance_score = sum(checks.values()) / len(checks) * 100
        
        return {
            'compliant': compliance_score >= 95,
            'score': compliance_score,
            'checks': checks,
            'requirements_met': sum(checks.values()),
            'total_requirements': len(checks)
        }
    
    def check_ffiec_compliance() -> Dict[str, Any]:
        """Check FFIEC compliance requirements."""
        checks = {
            'information_security': True,  # Placeholder
            'business_continuity': True,  # Placeholder
            'audit_requirements': True,  # Placeholder
            'risk_management': True,  # Placeholder
            'vendor_management': True  # Placeholder
        }
        
        compliance_score = sum(checks.values()) / len(checks) * 100
        
        return {
            'compliant': compliance_score >= 90,
            'score': compliance_score,
            'checks': checks,
            'requirements_met': sum(checks.values()),
            'total_requirements': len(checks)
        }
    
    def calculate_risk_score(scan_results: Dict[str, Any]) -> Dict[str, Any]:
        """Calculate overall risk score based on findings."""
        severity_weights = {
            'CRITICAL': 10,
            'HIGH': 7,
            'MEDIUM': 4,
            'LOW': 1
        }
        
        total_score = 0
        finding_counts = {'CRITICAL': 0, 'HIGH': 0, 'MEDIUM': 0, 'LOW': 0}
        
        # Count findings by severity
        for category in ['s3_findings', 'rds_findings', 'redis_findings', 'kms_findings']:
            for finding in scan_results.get(category, []):
                severity = finding.get('severity', 'LOW')
                finding_counts[severity] += 1
                total_score += severity_weights[severity]
        
        # Calculate risk score (0-10 scale)
        max_possible_score = 100  # Arbitrary max for scaling
        risk_score = min(10, (total_score / max_possible_score) * 10)
        
        return {
            'overall_risk': round(risk_score, 1),
            'total_findings': sum(finding_counts.values()),
            'critical_count': finding_counts['CRITICAL'],
            'high_count': finding_counts['HIGH'],
            'medium_count': finding_counts['MEDIUM'],
            'low_count': finding_counts['LOW'],
            'weighted_score': total_score
        }
    
    def send_to_security_hub(scan_results: Dict[str, Any]):
        """Send findings to AWS Security Hub."""
        try:
            findings_for_hub = []
            
            for category in ['s3_findings', 'rds_findings', 'redis_findings', 'kms_findings']:
                for finding in scan_results.get(category, []):
                    hub_finding = {
                        'SchemaVersion': '2018-10-08',
                        'Id': f"{scan_results['scan_id']}-{finding['type']}-{finding['resource']}",
                        'ProductArn': f"arn:aws:securityhub:{os.environ['SECURITY_HUB_REGION']}::product/mita-finance/storage-scanner",
                        'GeneratorId': 'mita-storage-security-scanner',
                        'AwsAccountId': boto3.Session().get_credentials().access_key.split(':')[4] if ':' in boto3.Session().get_credentials().access_key else '123456789012',
                        'Types': ['Software and Configuration Checks/Vulnerabilities/CVE'],
                        'CreatedAt': scan_results['timestamp'],
                        'UpdatedAt': scan_results['timestamp'],
                        'Severity': {
                            'Label': finding['severity']
                        },
                        'Title': finding['type'].replace('_', ' ').title(),
                        'Description': finding['description'],
                        'Resources': [
                            {
                                'Type': 'Other',
                                'Id': finding['resource'],
                                'Region': os.environ['SECURITY_HUB_REGION']
                            }
                        ],
                        'Remediation': {
                            'Recommendation': {
                                'Text': finding['remediation']
                            }
                        }
                    }
                    findings_for_hub.append(hub_finding)
            
            # Send findings in batches (Security Hub limit is 100 per call)
            batch_size = 100
            for i in range(0, len(findings_for_hub), batch_size):
                batch = findings_for_hub[i:i + batch_size]
                securityhub.batch_import_findings(Findings=batch)
                logger.info(f"Sent {len(batch)} findings to Security Hub")
                
        except Exception as e:
            logger.error(f"Failed to send findings to Security Hub: {e}")
    
    def record_security_metrics(scan_results: Dict[str, Any]):
        """Record security metrics to CloudWatch."""
        try:
            risk_assessment = scan_results['risk_assessment']
            
            metrics = [
                {
                    'MetricName': 'OverallRiskScore',
                    'Value': risk_assessment['overall_risk'],
                    'Unit': 'None'
                },
                {
                    'MetricName': 'CriticalFindings',
                    'Value': risk_assessment['critical_count'],
                    'Unit': 'Count'
                },
                {
                    'MetricName': 'HighFindings',
                    'Value': risk_assessment['high_count'],
                    'Unit': 'Count'
                },
                {
                    'MetricName': 'TotalFindings',
                    'Value': risk_assessment['total_findings'],
                    'Unit': 'Count'
                }
            ]
            
            cloudwatch.put_metric_data(
                Namespace='MITA/Security',
                MetricData=metrics
            )
            
            logger.info("Security metrics recorded to CloudWatch")
            
        except Exception as e:
            logger.error(f"Failed to record security metrics: {e}")
    
    def send_security_alert(scan_results: Dict[str, Any]):
        """Send high-priority security alerts."""
        try:
            risk_assessment = scan_results['risk_assessment']
            
            alert_message = f"""
            MITA Security Alert - High Risk Detected
            
            Scan ID: {scan_results['scan_id']}
            Overall Risk Score: {risk_assessment['overall_risk']}/10
            
            Critical Findings: {risk_assessment['critical_count']}
            High Findings: {risk_assessment['high_count']}
            Total Findings: {risk_assessment['total_findings']}
            
            Immediate Action Required:
            """
            
            # Add critical findings to alert
            for category in ['s3_findings', 'rds_findings', 'redis_findings', 'kms_findings']:
                critical_findings = [
                    f for f in scan_results.get(category, [])
                    if f.get('severity') == 'CRITICAL'
                ]
                
                for finding in critical_findings[:5]:  # Limit to first 5 per category
                    alert_message += f"\n- {finding['resource']}: {finding['description']}"
            
            alert_message += f"\n\nScan Timestamp: {scan_results['timestamp']}"
            
            sns.publish(
                TopicArn=os.environ['SNS_TOPIC_ARN'],
                Subject=" MITA Security Alert - High Risk Detected",
                Message=alert_message,
                MessageAttributes={
                    'severity': {
                        'DataType': 'String',
                        'StringValue': 'CRITICAL'
                    },
                    'scan_id': {
                        'DataType': 'String',
                        'StringValue': scan_results['scan_id']
                    }
                }
            )
            
            logger.info(f"Security alert sent for scan {scan_results['scan_id']}")
            
        except Exception as e:
            logger.error(f"Failed to send security alert: {e}")

---
# CronJob for regular security scanning
apiVersion: batch/v1
kind: CronJob
metadata:
  name: storage-security-scan
  namespace: mita-production
  labels:
    app.kubernetes.io/name: mita
    app.kubernetes.io/component: security-scanning
    app.kubernetes.io/part-of: mita-finance
spec:
  schedule: "0 6 * * *"  # Daily at 6 AM UTC
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 7
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app.kubernetes.io/name: storage-security-scan
            app.kubernetes.io/component: security-scanning
            app.kubernetes.io/part-of: mita-finance
        spec:
          restartPolicy: OnFailure
          serviceAccountName: mita-security-scanner
          containers:
          - name: trivy-scanner
            image: aquasec/trivy:latest
            command:
            - /bin/sh
            - -c
            - |
              echo "Starting Trivy security scan..."
              
              # Scan for filesystem vulnerabilities
              trivy fs --format json --output /tmp/trivy-fs-report.json /
              
              # Scan container images
              trivy image --format json --output /tmp/trivy-image-report.json postgres:15
              trivy image --format json --output /tmp/trivy-redis-report.json redis:7.0
              
              # Upload results to S3
              if [ -n "$AWS_ROLE_ARN" ]; then
                aws s3 cp /tmp/trivy-fs-report.json s3://$SECURITY_REPORTS_BUCKET/trivy/$(date +%Y/%m/%d)/fs-report.json
                aws s3 cp /tmp/trivy-image-report.json s3://$SECURITY_REPORTS_BUCKET/trivy/$(date +%Y/%m/%d)/postgres-image-report.json
                aws s3 cp /tmp/trivy-redis-report.json s3://$SECURITY_REPORTS_BUCKET/trivy/$(date +%Y/%m/%d)/redis-image-report.json
              fi
              
              echo "Trivy security scan completed"
            
            env:
            - name: AWS_ROLE_ARN
              value: "arn:aws:iam::ACCOUNT-ID:role/mita-security-scanner-role"
            - name: SECURITY_REPORTS_BUCKET
              value: "mita-finance-security-reports"
            
            resources:
              requests:
                memory: "512Mi"
                cpu: "200m"
              limits:
                memory: "1Gi"
                cpu: "500m"
            
            volumeMounts:
            - name: tmp
              mountPath: /tmp
          
          volumes:
          - name: tmp
            emptyDir: {}

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: mita-security-scanner
  namespace: mita-production
  labels:
    app.kubernetes.io/name: mita
    app.kubernetes.io/component: security-scanning
    app.kubernetes.io/part-of: mita-finance
  annotations:
    eks.amazonaws.com/role-arn: "arn:aws:iam::ACCOUNT-ID:role/mita-security-scanner-role"