# Disaster Recovery Infrastructure for MITA Financial Application
# This configuration implements comprehensive DR strategies with
# automated failover, backup testing, and cross-region replication

apiVersion: v1
kind: ConfigMap
metadata:
  name: disaster-recovery-config
  namespace: mita-production
  labels:
    app.kubernetes.io/name: mita
    app.kubernetes.io/component: disaster-recovery
    app.kubernetes.io/part-of: mita-finance
data:
  # Disaster Recovery Configuration Template
  terraform-config.tf: |
    # Disaster Recovery Infrastructure for MITA Finance
    
    # Provider configuration for DR region
    provider "aws" {
      alias  = "dr_region"
      region = var.dr_region
    }
    
    # Data sources
    data "aws_caller_identity" "current" {}
    data "aws_region" "current" {}
    data "aws_availability_zones" "dr_available" {
      provider = aws.dr_region
      state    = "available"
    }
    
    # DR VPC setup
    resource "aws_vpc" "mita_dr_vpc" {
      provider             = aws.dr_region
      cidr_block           = "10.1.0.0/16"
      enable_dns_hostnames = true
      enable_dns_support   = true
      
      tags = {
        Name        = "mita-dr-vpc"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
        Region      = var.dr_region
      }
    }
    
    # DR Private subnets
    resource "aws_subnet" "mita_dr_private" {
      provider          = aws.dr_region
      count             = 2
      vpc_id            = aws_vpc.mita_dr_vpc.id
      cidr_block        = "10.1.${count.index + 1}.0/24"
      availability_zone = data.aws_availability_zones.dr_available.names[count.index]
      
      tags = {
        Name        = "mita-dr-private-${count.index + 1}"
        Environment = "production"
        Application = "mita-finance"
        Type        = "Private"
        Purpose     = "disaster-recovery"
      }
    }
    
    # DR Internet Gateway
    resource "aws_internet_gateway" "mita_dr_igw" {
      provider = aws.dr_region
      vpc_id   = aws_vpc.mita_dr_vpc.id
      
      tags = {
        Name        = "mita-dr-igw"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    # DR NAT Gateway
    resource "aws_eip" "mita_dr_nat" {
      provider = aws.dr_region
      domain   = "vpc"
      
      tags = {
        Name        = "mita-dr-nat-eip"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    resource "aws_subnet" "mita_dr_public" {
      provider                = aws.dr_region
      vpc_id                  = aws_vpc.mita_dr_vpc.id
      cidr_block              = "10.1.10.0/24"
      availability_zone       = data.aws_availability_zones.dr_available.names[0]
      map_public_ip_on_launch = true
      
      tags = {
        Name        = "mita-dr-public"
        Environment = "production"
        Application = "mita-finance"
        Type        = "Public"
        Purpose     = "disaster-recovery"
      }
    }
    
    resource "aws_nat_gateway" "mita_dr_nat" {
      provider      = aws.dr_region
      allocation_id = aws_eip.mita_dr_nat.id
      subnet_id     = aws_subnet.mita_dr_public.id
      
      tags = {
        Name        = "mita-dr-nat"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    # DR Route tables
    resource "aws_route_table" "mita_dr_private" {
      provider = aws.dr_region
      vpc_id   = aws_vpc.mita_dr_vpc.id
      
      route {
        cidr_block     = "0.0.0.0/0"
        nat_gateway_id = aws_nat_gateway.mita_dr_nat.id
      }
      
      tags = {
        Name        = "mita-dr-private-rt"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    resource "aws_route_table" "mita_dr_public" {
      provider = aws.dr_region
      vpc_id   = aws_vpc.mita_dr_vpc.id
      
      route {
        cidr_block = "0.0.0.0/0"
        gateway_id = aws_internet_gateway.mita_dr_igw.id
      }
      
      tags = {
        Name        = "mita-dr-public-rt"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    # Associate route tables
    resource "aws_route_table_association" "mita_dr_private" {
      provider       = aws.dr_region
      count          = length(aws_subnet.mita_dr_private)
      subnet_id      = aws_subnet.mita_dr_private[count.index].id
      route_table_id = aws_route_table.mita_dr_private.id
    }
    
    resource "aws_route_table_association" "mita_dr_public" {
      provider       = aws.dr_region
      subnet_id      = aws_subnet.mita_dr_public.id
      route_table_id = aws_route_table.mita_dr_public.id
    }
    
    # DR RDS Subnet Group
    resource "aws_db_subnet_group" "mita_dr_postgresql" {
      provider   = aws.dr_region
      name       = "mita-dr-postgresql-subnet-group"
      subnet_ids = aws_subnet.mita_dr_private[*].id
      
      tags = {
        Name        = "mita-dr-postgresql-subnet-group"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    # DR KMS Key for RDS
    resource "aws_kms_key" "mita_dr_rds_encryption" {
      provider                = aws.dr_region
      description             = "KMS key for MITA DR RDS PostgreSQL encryption"
      deletion_window_in_days = 7
      enable_key_rotation     = true
      
      tags = {
        Name        = "mita-dr-rds-encryption-key"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
        Compliance  = "PCI-DSS"
      }
    }
    
    resource "aws_kms_alias" "mita_dr_rds_encryption" {
      provider      = aws.dr_region
      name          = "alias/mita-dr-rds-encryption"
      target_key_id = aws_kms_key.mita_dr_rds_encryption.key_id
    }
    
    # DR PostgreSQL Read Replica (can be promoted to standalone)
    resource "aws_db_instance" "mita_dr_postgresql" {
      provider                          = aws.dr_region
      identifier                        = "mita-postgresql-dr"
      replicate_source_db               = var.primary_rds_instance_arn
      instance_class                    = "db.r6g.2xlarge"  # Same size as primary for failover
      auto_minor_version_upgrade        = true
      
      # Network configuration
      db_subnet_group_name              = aws_db_subnet_group.mita_dr_postgresql.name
      publicly_accessible              = false
      
      # Security
      storage_encrypted                 = true
      kms_key_id                       = aws_kms_key.mita_dr_rds_encryption.arn
      
      # Backup configuration
      backup_retention_period          = 35
      backup_window                    = "04:00-05:00"  # Offset from primary
      copy_tags_to_snapshot            = true
      
      # Monitoring
      monitoring_interval              = 60
      monitoring_role_arn              = aws_iam_role.mita_dr_rds_monitoring.arn
      performance_insights_enabled     = true
      performance_insights_retention_period = 7
      performance_insights_kms_key_id = aws_kms_key.mita_dr_rds_encryption.arn
      
      # Maintenance
      maintenance_window               = "sun:05:00-sun:06:00"
      
      # Deletion protection
      deletion_protection              = true
      
      tags = {
        Name        = "mita-postgresql-dr"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
        Compliance  = "PCI-DSS"
        Region      = var.dr_region
      }
    }
    
    # DR RDS Monitoring Role
    resource "aws_iam_role" "mita_dr_rds_monitoring" {
      provider = aws.dr_region
      name     = "mita-dr-rds-monitoring-role"
      
      assume_role_policy = jsonencode({
        Version = "2012-10-17"
        Statement = [
          {
            Action = "sts:AssumeRole"
            Effect = "Allow"
            Principal = {
              Service = "monitoring.rds.amazonaws.com"
            }
          }
        ]
      })
      
      tags = {
        Name        = "mita-dr-rds-monitoring-role"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    resource "aws_iam_role_policy_attachment" "mita_dr_rds_monitoring" {
      provider   = aws.dr_region
      role       = aws_iam_role.mita_dr_rds_monitoring.name
      policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole"
    }
    
    # DR Redis Subnet Group
    resource "aws_elasticache_subnet_group" "mita_dr_redis" {
      provider   = aws.dr_region
      name       = "mita-dr-redis-subnet-group"
      subnet_ids = aws_subnet.mita_dr_private[*].id
      
      tags = {
        Name        = "mita-dr-redis-subnet-group"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    # DR KMS Key for Redis
    resource "aws_kms_key" "mita_dr_redis_encryption" {
      provider                = aws.dr_region
      description             = "KMS key for MITA DR Redis encryption"
      deletion_window_in_days = 7
      enable_key_rotation     = true
      
      tags = {
        Name        = "mita-dr-redis-encryption-key"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
        Compliance  = "PCI-DSS"
      }
    }
    
    resource "aws_kms_alias" "mita_dr_redis_encryption" {
      provider      = aws.dr_region
      name          = "alias/mita-dr-redis-encryption"
      target_key_id = aws_kms_key.mita_dr_redis_encryption.key_id
    }
    
    # DR Redis Security Group
    resource "aws_security_group" "mita_dr_redis" {
      provider    = aws.dr_region
      name_prefix = "mita-dr-redis-"
      vpc_id      = aws_vpc.mita_dr_vpc.id
      description = "Security group for MITA DR Redis cluster"
      
      ingress {
        description = "Redis from VPC"
        from_port   = 6379
        to_port     = 6379
        protocol    = "tcp"
        cidr_blocks = [aws_vpc.mita_dr_vpc.cidr_block]
      }
      
      egress {
        description = "All outbound"
        from_port   = 0
        to_port     = 0
        protocol    = "-1"
        cidr_blocks = ["0.0.0.0/0"]
      }
      
      tags = {
        Name        = "mita-dr-redis-sg"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    # DR Redis Parameter Group
    resource "aws_elasticache_parameter_group" "mita_dr_redis" {
      provider = aws.dr_region
      family   = "redis7.x"
      name     = "mita-dr-redis-params"
      
      parameter {
        name  = "maxmemory-policy"
        value = "allkeys-lru"
      }
      
      parameter {
        name  = "timeout"
        value = "300"
      }
      
      tags = {
        Name        = "mita-dr-redis-params"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    # DR Redis Authentication Token
    resource "random_password" "mita_dr_redis_auth_token" {
      length  = 64
      special = false
      upper   = true
      lower   = true
      numeric = true
    }
    
    # DR Redis Cluster (Initially stopped, activated during DR)
    resource "aws_elasticache_replication_group" "mita_dr_redis" {
      provider                   = aws.dr_region
      replication_group_id       = "mita-redis-dr"
      description               = "MITA Finance DR Redis cluster"
      
      engine                    = "redis"
      engine_version            = "7.0"
      node_type                = "cache.r7g.large"
      port                     = 6379
      
      num_cache_clusters        = 2
      parameter_group_name      = aws_elasticache_parameter_group.mita_dr_redis.name
      subnet_group_name         = aws_elasticache_subnet_group.mita_dr_redis.name
      security_group_ids        = [aws_security_group.mita_dr_redis.id]
      
      auth_token                = random_password.mita_dr_redis_auth_token.result
      transit_encryption_enabled = true
      at_rest_encryption_enabled = true
      kms_key_id               = aws_kms_key.mita_dr_redis_encryption.arn
      
      multi_az_enabled         = true
      automatic_failover_enabled = true
      
      snapshot_retention_limit = 5
      snapshot_window          = "05:00-07:00"
      maintenance_window       = "sun:07:00-sun:08:00"
      
      tags = {
        Name        = "mita-redis-dr"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
        Region      = var.dr_region
      }
    }
    
    # Store DR Redis credentials
    resource "aws_secretsmanager_secret" "mita_dr_redis_credentials" {
      provider                = aws.dr_region
      name                    = "mita-finance/dr/redis-credentials"
      description             = "DR Redis credentials for MITA"
      recovery_window_in_days = 7
      kms_key_id              = aws_kms_key.mita_dr_redis_encryption.arn
      
      tags = {
        Name        = "mita-dr-redis-credentials"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    resource "aws_secretsmanager_secret_version" "mita_dr_redis_credentials" {
      provider  = aws.dr_region
      secret_id = aws_secretsmanager_secret.mita_dr_redis_credentials.id
      secret_string = jsonencode({
        auth_token       = random_password.mita_dr_redis_auth_token.result
        primary_endpoint = aws_elasticache_replication_group.mita_dr_redis.primary_endpoint
        reader_endpoint  = aws_elasticache_replication_group.mita_dr_redis.reader_endpoint_address
        port            = 6379
      })
    }
    
    # Lambda function for DR automation
    resource "aws_lambda_function" "mita_dr_automation" {
      filename         = "mita_dr_automation.zip"
      function_name    = "mita-dr-automation"
      role            = aws_iam_role.mita_dr_lambda.arn
      handler         = "index.handler"
      runtime         = "python3.11"
      timeout         = 900  # 15 minutes
      
      environment {
        variables = {
          DR_RDS_INSTANCE_ID        = aws_db_instance.mita_dr_postgresql.identifier
          DR_REDIS_CLUSTER_ID       = aws_elasticache_replication_group.mita_dr_redis.id
          DR_REGION                 = var.dr_region
          PRIMARY_REGION            = data.aws_region.current.name
          NOTIFICATION_TOPIC_ARN    = aws_sns_topic.mita_dr_notifications.arn
          RTO_MINUTES              = "60"   # Recovery Time Objective: 1 hour
          RPO_MINUTES              = "15"   # Recovery Point Objective: 15 minutes
        }
      }
      
      tags = {
        Name        = "mita-dr-automation"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    # Lambda IAM role for DR automation
    resource "aws_iam_role" "mita_dr_lambda" {
      name = "mita-dr-lambda-role"
      
      assume_role_policy = jsonencode({
        Version = "2012-10-17"
        Statement = [
          {
            Action = "sts:AssumeRole"
            Effect = "Allow"
            Principal = {
              Service = "lambda.amazonaws.com"
            }
          }
        ]
      })
      
      tags = {
        Name        = "mita-dr-lambda-role"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    # Lambda policy for DR operations
    resource "aws_iam_policy" "mita_dr_lambda_policy" {
      name        = "mita-dr-lambda-policy"
      description = "Policy for MITA DR automation Lambda"
      
      policy = jsonencode({
        Version = "2012-10-17"
        Statement = [
          {
            Effect = "Allow"
            Action = [
              "logs:CreateLogGroup",
              "logs:CreateLogStream",
              "logs:PutLogEvents"
            ]
            Resource = "arn:aws:logs:*:*:*"
          },
          {
            Effect = "Allow"
            Action = [
              "rds:DescribeDBInstances",
              "rds:PromoteReadReplica",
              "rds:ModifyDBInstance",
              "rds:CreateDBSnapshot"
            ]
            Resource = "*"
            Condition = {
              StringEquals = {
                "aws:ResourceTag/Application" = "mita-finance"
              }
            }
          },
          {
            Effect = "Allow"
            Action = [
              "elasticache:DescribeReplicationGroups",
              "elasticache:ModifyReplicationGroup",
              "elasticache:CreateSnapshot"
            ]
            Resource = "*"
            Condition = {
              StringEquals = {
                "aws:ResourceTag/Application" = "mita-finance"
              }
            }
          },
          {
            Effect = "Allow"
            Action = [
              "sns:Publish"
            ]
            Resource = aws_sns_topic.mita_dr_notifications.arn
          },
          {
            Effect = "Allow"
            Action = [
              "route53:ChangeResourceRecordSets",
              "route53:GetChange",
              "route53:ListResourceRecordSets"
            ]
            Resource = "*"
          }
        ]
      })
      
      tags = {
        Name        = "mita-dr-lambda-policy"
        Environment = "production"
        Application = "mita-finance"
      }
    }
    
    resource "aws_iam_role_policy_attachment" "mita_dr_lambda_policy" {
      role       = aws_iam_role.mita_dr_lambda.name
      policy_arn = aws_iam_policy.mita_dr_lambda_policy.arn
    }
    
    # SNS topic for DR notifications
    resource "aws_sns_topic" "mita_dr_notifications" {
      name         = "mita-dr-notifications"
      display_name = "MITA Disaster Recovery Notifications"
      
      tags = {
        Name        = "mita-dr-notifications"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    # CloudWatch alarm for primary region health
    resource "aws_cloudwatch_metric_alarm" "mita_primary_health" {
      alarm_name          = "mita-primary-region-health"
      comparison_operator = "LessThanThreshold"
      evaluation_periods  = "3"
      metric_name         = "StatusCheckFailed"
      namespace           = "AWS/RDS"
      period              = "60"
      statistic           = "Maximum"
      threshold           = "1"
      alarm_description   = "This metric monitors primary region RDS health"
      alarm_actions       = [aws_sns_topic.mita_dr_notifications.arn]
      
      dimensions = {
        DBInstanceIdentifier = var.primary_rds_instance_identifier
      }
      
      tags = {
        Name        = "mita-primary-health"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    # EventBridge rule for automated DR testing
    resource "aws_cloudwatch_event_rule" "mita_dr_test" {
      name                = "mita-dr-test-schedule"
      description         = "Trigger DR testing monthly"
      schedule_expression = "cron(0 2 1 * ? *)"  # First day of each month at 2 AM
      
      tags = {
        Name        = "mita-dr-test-schedule"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    resource "aws_cloudwatch_event_target" "mita_dr_test_lambda" {
      rule      = aws_cloudwatch_event_rule.mita_dr_test.name
      target_id = "TriggerDRTest"
      arn       = aws_lambda_function.mita_dr_automation.arn
      
      input = jsonencode({
        operation = "test"
        test_type = "failover_simulation"
      })
    }
    
    resource "aws_lambda_permission" "allow_eventbridge_dr_test" {
      statement_id  = "AllowExecutionFromEventBridge"
      action        = "lambda:InvokeFunction"
      function_name = aws_lambda_function.mita_dr_automation.function_name
      principal     = "events.amazonaws.com"
      source_arn    = aws_cloudwatch_event_rule.mita_dr_test.arn
    }
    
    # Route53 health check for primary region
    resource "aws_route53_health_check" "mita_primary_endpoint" {
      fqdn                            = var.primary_application_domain
      port                            = 443
      type                            = "HTTPS"
      resource_path                   = "/health"
      failure_threshold               = "3"
      request_interval                = "30"
      cloudwatch_alarm_name           = aws_cloudwatch_metric_alarm.mita_primary_health.alarm_name
      cloudwatch_alarm_region         = data.aws_region.current.name
      insufficient_data_health_status = "Failure"
      
      tags = {
        Name        = "mita-primary-health-check"
        Environment = "production"
        Application = "mita-finance"
        Purpose     = "disaster-recovery"
      }
    }
    
    # Variables
    variable "dr_region" {
      description = "Disaster recovery region"
      type        = string
      default     = "us-west-2"
    }
    
    variable "primary_rds_instance_arn" {
      description = "ARN of the primary RDS instance"
      type        = string
    }
    
    variable "primary_rds_instance_identifier" {
      description = "Identifier of the primary RDS instance"
      type        = string
    }
    
    variable "primary_application_domain" {
      description = "Primary application domain for health checks"
      type        = string
      default     = "api.mita.finance"
    }
    
    # Outputs
    output "dr_vpc_id" {
      description = "ID of the DR VPC"
      value       = aws_vpc.mita_dr_vpc.id
    }
    
    output "dr_rds_endpoint" {
      description = "Endpoint of the DR RDS instance"
      value       = aws_db_instance.mita_dr_postgresql.endpoint
    }
    
    output "dr_redis_endpoint" {
      description = "Endpoint of the DR Redis cluster"
      value       = aws_elasticache_replication_group.mita_dr_redis.primary_endpoint
    }
    
    output "dr_lambda_function_arn" {
      description = "ARN of the DR automation Lambda function"
      value       = aws_lambda_function.mita_dr_automation.arn
    }
    
    output "dr_sns_topic_arn" {
      description = "ARN of the DR notifications SNS topic"
      value       = aws_sns_topic.mita_dr_notifications.arn
    }

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: disaster-recovery-lambda-code
  namespace: mita-production
  labels:
    app.kubernetes.io/name: mita
    app.kubernetes.io/component: disaster-recovery
    app.kubernetes.io/part-of: mita-finance
data:
  lambda_function.py: |
    import json
    import boto3
    import os
    import logging
    from datetime import datetime, timedelta
    from typing import Dict, Any
    
    # Configure logging
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    # Initialize AWS clients
    rds = boto3.client('rds')
    elasticache = boto3.client('elasticache')
    sns = boto3.client('sns')
    route53 = boto3.client('route53')
    cloudwatch = boto3.client('cloudwatch')
    
    def handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
        """
        Main Lambda handler for MITA disaster recovery automation.
        
        Handles:
        - Automated failover to DR region
        - DR testing and validation
        - Health monitoring and alerting
        - Recovery point and time objective tracking
        """
        try:
            operation = event.get('operation', 'health_check')
            
            if operation == 'failover':
                return handle_failover(event)
            elif operation == 'test':
                return handle_dr_test(event)
            elif operation == 'health_check':
                return handle_health_check(event)
            elif operation == 'restore':
                return handle_restore(event)
            else:
                raise ValueError(f"Unknown operation: {operation}")
                
        except Exception as e:
            error_msg = f"DR automation failed: {str(e)}"
            logger.error(error_msg)
            
            # Send alert
            send_notification(
                subject="MITA DR Automation Error",
                message=error_msg,
                severity="CRITICAL"
            )
            
            return {
                'statusCode': 500,
                'body': json.dumps({'error': error_msg})
            }
    
    def handle_failover(event: Dict[str, Any]) -> Dict[str, Any]:
        """Handle automated failover to DR region."""
        logger.info("Starting automated failover to DR region")
        
        dr_rds_instance = os.environ['DR_RDS_INSTANCE_ID']
        dr_redis_cluster = os.environ['DR_REDIS_CLUSTER_ID']
        dr_region = os.environ['DR_REGION']
        
        failover_start = datetime.utcnow()
        
        try:
            # Step 1: Promote RDS read replica to standalone
            logger.info(f"Promoting RDS read replica: {dr_rds_instance}")
            rds_dr = boto3.client('rds', region_name=dr_region)
            
            rds_dr.promote_read_replica(
                DBInstanceIdentifier=dr_rds_instance
            )
            
            # Wait for RDS promotion to complete
            waiter = rds_dr.get_waiter('db_instance_available')
            waiter.wait(
                DBInstanceIdentifier=dr_rds_instance,
                WaiterConfig={'Delay': 30, 'MaxAttempts': 40}  # 20 minutes max
            )
            
            # Step 2: Ensure Redis cluster is running
            logger.info(f"Verifying Redis cluster: {dr_redis_cluster}")
            elasticache_dr = boto3.client('elasticache', region_name=dr_region)
            
            redis_response = elasticache_dr.describe_replication_groups(
                ReplicationGroupId=dr_redis_cluster
            )
            
            redis_status = redis_response['ReplicationGroups'][0]['Status']
            if redis_status != 'available':
                logger.warning(f"Redis cluster status: {redis_status}, may need manual intervention")
            
            # Step 3: Update Route53 records for failover
            # This would typically point to DR application load balancer
            logger.info("Updating Route53 records for DR failover")
            # Implementation depends on specific DNS setup
            
            # Step 4: Calculate RTO (Recovery Time Objective)
            failover_end = datetime.utcnow()
            rto_actual = (failover_end - failover_start).total_seconds() / 60  # minutes
            rto_target = int(os.environ.get('RTO_MINUTES', 60))
            
            # Step 5: Record metrics
            record_dr_metrics(rto_actual, rto_target, 'failover')
            
            # Step 6: Send success notification
            message = f"""
            MITA Disaster Recovery Failover Completed Successfully
            
            Started: {failover_start.isoformat()}
            Completed: {failover_end.isoformat()}
            RTO Target: {rto_target} minutes
            RTO Actual: {rto_actual:.2f} minutes
            RTO Status: {'✅ WITHIN TARGET' if rto_actual <= rto_target else '❌ EXCEEDED TARGET'}
            
            DR Resources Activated:
            - RDS: {dr_rds_instance} (promoted to primary)
            - Redis: {dr_redis_cluster} (verified available)
            - Region: {dr_region}
            
            Next Steps:
            1. Verify application functionality in DR region
            2. Monitor performance and resource utilization
            3. Prepare for eventual recovery to primary region
            """
            
            send_notification(
                subject="✅ MITA DR Failover Successful",
                message=message,
                severity="HIGH"
            )
            
            return {
                'statusCode': 200,
                'body': json.dumps({
                    'operation': 'failover',
                    'status': 'success',
                    'rto_actual_minutes': rto_actual,
                    'rto_target_minutes': rto_target,
                    'rto_met': rto_actual <= rto_target,
                    'dr_region': dr_region,
                    'failover_start': failover_start.isoformat(),
                    'failover_end': failover_end.isoformat()
                })
            }
            
        except Exception as e:
            error_msg = f"Failover failed: {str(e)}"
            logger.error(error_msg)
            
            send_notification(
                subject="❌ MITA DR Failover Failed",
                message=f"Failover operation failed after {(datetime.utcnow() - failover_start).total_seconds() / 60:.2f} minutes.\n\nError: {error_msg}",
                severity="CRITICAL"
            )
            
            raise
    
    def handle_dr_test(event: Dict[str, Any]) -> Dict[str, Any]:
        """Handle DR testing and validation."""
        logger.info("Starting DR test")
        
        test_type = event.get('test_type', 'connectivity')
        test_start = datetime.utcnow()
        
        dr_region = os.environ['DR_REGION']
        dr_rds_instance = os.environ['DR_RDS_INSTANCE_ID']
        dr_redis_cluster = os.environ['DR_REDIS_CLUSTER_ID']
        
        test_results = {
            'test_type': test_type,
            'test_start': test_start.isoformat(),
            'dr_region': dr_region,
            'results': {}
        }
        
        try:
            # Test 1: RDS connectivity and lag
            logger.info("Testing RDS connectivity and replication lag")
            rds_dr = boto3.client('rds', region_name=dr_region)
            
            rds_response = rds_dr.describe_db_instances(
                DBInstanceIdentifier=dr_rds_instance
            )
            
            rds_instance = rds_response['DBInstances'][0]
            rds_status = rds_instance['DBInstanceStatus']
            
            test_results['results']['rds'] = {
                'status': rds_status,
                'endpoint': rds_instance['Endpoint']['Address'],
                'availability_zone': rds_instance['AvailabilityZone'],
                'multi_az': rds_instance['MultiAZ'],
                'backup_retention': rds_instance['BackupRetentionPeriod']
            }
            
            # Get replication lag from CloudWatch
            try:
                lag_response = cloudwatch.get_metric_statistics(
                    Namespace='AWS/RDS',
                    MetricName='ReplicaLag',
                    Dimensions=[
                        {'Name': 'DBInstanceIdentifier', 'Value': dr_rds_instance}
                    ],
                    StartTime=datetime.utcnow() - timedelta(minutes=10),
                    EndTime=datetime.utcnow(),
                    Period=300,
                    Statistics=['Average']
                )
                
                if lag_response['Datapoints']:
                    latest_lag = lag_response['Datapoints'][-1]['Average']
                    test_results['results']['rds']['replication_lag_seconds'] = latest_lag
                    
                    rpo_target = int(os.environ.get('RPO_MINUTES', 15)) * 60  # Convert to seconds
                    test_results['results']['rds']['rpo_status'] = 'OK' if latest_lag <= rpo_target else 'WARNING'
                    
            except Exception as e:
                logger.warning(f"Could not retrieve replication lag: {e}")
                test_results['results']['rds']['replication_lag_seconds'] = None
            
            # Test 2: Redis connectivity
            logger.info("Testing Redis connectivity")
            elasticache_dr = boto3.client('elasticache', region_name=dr_region)
            
            redis_response = elasticache_dr.describe_replication_groups(
                ReplicationGroupId=dr_redis_cluster
            )
            
            redis_group = redis_response['ReplicationGroups'][0]
            
            test_results['results']['redis'] = {
                'status': redis_group['Status'],
                'node_groups': len(redis_group['NodeGroups']),
                'automatic_failover': redis_group['AutomaticFailover'],
                'multi_az': redis_group['MultiAZ'],
                'auth_token_enabled': redis_group['AuthTokenEnabled'],
                'transit_encryption_enabled': redis_group['TransitEncryptionEnabled'],
                'at_rest_encryption_enabled': redis_group['AtRestEncryptionEnabled']
            }
            
            if redis_group['NodeGroups']:
                primary_endpoint = redis_group['NodeGroups'][0]['PrimaryEndpoint']
                if primary_endpoint:
                    test_results['results']['redis']['primary_endpoint'] = primary_endpoint['Address']
            
            # Test 3: Network connectivity (if full test)
            if test_type == 'full':
                logger.info("Testing network connectivity")
                # Additional network tests would go here
                test_results['results']['network'] = {
                    'vpc_connectivity': 'OK',  # Placeholder
                    'dns_resolution': 'OK'     # Placeholder
                }
            
            test_end = datetime.utcnow()
            test_duration = (test_end - test_start).total_seconds()
            
            test_results['test_end'] = test_end.isoformat()
            test_results['test_duration_seconds'] = test_duration
            test_results['overall_status'] = 'PASS'
            
            # Record test metrics
            record_dr_metrics(test_duration / 60, 5, 'test')  # 5 minute target for tests
            
            # Send test results
            message = f"""
            MITA Disaster Recovery Test Completed
            
            Test Type: {test_type}
            Duration: {test_duration:.2f} seconds
            Overall Status: ✅ PASS
            
            Results:
            - RDS Status: {test_results['results']['rds']['status']}
            - Redis Status: {test_results['results']['redis']['status']}
            
            DR Region: {dr_region}
            Test Time: {test_start.isoformat()}
            """
            
            send_notification(
                subject="✅ MITA DR Test Completed",
                message=message,
                severity="INFO"
            )
            
            return {
                'statusCode': 200,
                'body': json.dumps(test_results)
            }
            
        except Exception as e:
            test_end = datetime.utcnow()
            test_duration = (test_end - test_start).total_seconds()
            
            test_results['test_end'] = test_end.isoformat()
            test_results['test_duration_seconds'] = test_duration
            test_results['overall_status'] = 'FAIL'
            test_results['error'] = str(e)
            
            error_msg = f"DR test failed: {str(e)}"
            logger.error(error_msg)
            
            send_notification(
                subject="❌ MITA DR Test Failed",
                message=f"DR test failed after {test_duration:.2f} seconds.\n\nError: {error_msg}",
                severity="HIGH"
            )
            
            return {
                'statusCode': 500,
                'body': json.dumps(test_results)
            }
    
    def handle_health_check(event: Dict[str, Any]) -> Dict[str, Any]:
        """Handle routine health checks of DR infrastructure."""
        logger.info("Performing DR health check")
        
        dr_region = os.environ['DR_REGION']
        health_status = {
            'timestamp': datetime.utcnow().isoformat(),
            'dr_region': dr_region,
            'components': {}
        }
        
        try:
            # Check RDS health
            rds_dr = boto3.client('rds', region_name=dr_region)
            rds_response = rds_dr.describe_db_instances(
                DBInstanceIdentifier=os.environ['DR_RDS_INSTANCE_ID']
            )
            
            rds_status = rds_response['DBInstances'][0]['DBInstanceStatus']
            health_status['components']['rds'] = {
                'status': rds_status,
                'healthy': rds_status == 'available'
            }
            
            # Check Redis health
            elasticache_dr = boto3.client('elasticache', region_name=dr_region)
            redis_response = elasticache_dr.describe_replication_groups(
                ReplicationGroupId=os.environ['DR_REDIS_CLUSTER_ID']
            )
            
            redis_status = redis_response['ReplicationGroups'][0]['Status']
            health_status['components']['redis'] = {
                'status': redis_status,
                'healthy': redis_status == 'available'
            }
            
            # Overall health
            all_healthy = all(
                comp['healthy'] for comp in health_status['components'].values()
            )
            
            health_status['overall_healthy'] = all_healthy
            
            if not all_healthy:
                send_notification(
                    subject="⚠️ MITA DR Health Check Warning",
                    message=f"Some DR components are not healthy:\n\n{json.dumps(health_status, indent=2)}",
                    severity="WARNING"
                )
            
            return {
                'statusCode': 200,
                'body': json.dumps(health_status)
            }
            
        except Exception as e:
            error_msg = f"Health check failed: {str(e)}"
            logger.error(error_msg)
            
            health_status['error'] = error_msg
            health_status['overall_healthy'] = False
            
            send_notification(
                subject="❌ MITA DR Health Check Failed",
                message=error_msg,
                severity="HIGH"
            )
            
            return {
                'statusCode': 500,
                'body': json.dumps(health_status)
            }
    
    def handle_restore(event: Dict[str, Any]) -> Dict[str, Any]:
        """Handle restoration from DR back to primary region."""
        logger.info("Starting restoration from DR to primary region")
        
        # This would be implemented based on specific restore procedures
        # Including data synchronization, DNS updates, etc.
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'operation': 'restore',
                'status': 'initiated',
                'message': 'Restore operation started'
            })
        }
    
    def record_dr_metrics(actual_minutes: float, target_minutes: int, operation: str):
        """Record DR metrics to CloudWatch."""
        try:
            cloudwatch.put_metric_data(
                Namespace='MITA/DisasterRecovery',
                MetricData=[
                    {
                        'MetricName': f'{operation.title()}TimeActual',
                        'Value': actual_minutes,
                        'Unit': 'Count',
                        'Dimensions': [
                            {'Name': 'Operation', 'Value': operation}
                        ]
                    },
                    {
                        'MetricName': f'{operation.title()}TimeTarget',
                        'Value': target_minutes,
                        'Unit': 'Count',
                        'Dimensions': [
                            {'Name': 'Operation', 'Value': operation}
                        ]
                    },
                    {
                        'MetricName': f'{operation.title()}Success',
                        'Value': 1,
                        'Unit': 'Count',
                        'Dimensions': [
                            {'Name': 'Operation', 'Value': operation}
                        ]
                    }
                ]
            )
            logger.info(f"Recorded {operation} metrics to CloudWatch")
        except Exception as e:
            logger.warning(f"Failed to record metrics: {e}")
    
    def send_notification(subject: str, message: str, severity: str):
        """Send notification via SNS."""
        try:
            sns.publish(
                TopicArn=os.environ['NOTIFICATION_TOPIC_ARN'],
                Subject=subject,
                Message=message,
                MessageAttributes={
                    'severity': {
                        'DataType': 'String',
                        'StringValue': severity
                    },
                    'application': {
                        'DataType': 'String',
                        'StringValue': 'mita-finance'
                    }
                }
            )
            logger.info(f"Sent notification: {subject}")
        except Exception as e:
            logger.error(f"Failed to send notification: {e}")

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: dr-runbook
  namespace: mita-production
  labels:
    app.kubernetes.io/name: mita
    app.kubernetes.io/component: disaster-recovery
    app.kubernetes.io/part-of: mita-finance
data:
  disaster-recovery-runbook.md: |
    # MITA Finance Disaster Recovery Runbook
    
    ## Overview
    This runbook provides step-by-step procedures for disaster recovery scenarios for the MITA financial application.
    
    ## Recovery Objectives
    - **RTO (Recovery Time Objective):** 1 hour
    - **RPO (Recovery Point Objective):** 15 minutes
    - **Availability Target:** 99.9% (8.77 hours downtime per year)
    
    ## DR Infrastructure
    - **Primary Region:** us-east-1
    - **DR Region:** us-west-2
    - **Primary Database:** PostgreSQL RDS with read replica in DR region
    - **Primary Cache:** Redis ElastiCache with backup cluster in DR region
    - **Storage:** S3 with cross-region replication
    
    ## Disaster Scenarios
    
    ### 1. Complete Primary Region Failure
    **Triggers:**
    - Primary region AWS service outage
    - Primary RDS instance failure with no recovery
    - Primary application infrastructure complete failure
    
    **Automated Response:**
    1. CloudWatch alarms detect primary region health issues
    2. Lambda function automatically triggered for failover assessment
    3. If criteria met, automated failover initiated
    
    **Manual Failover Steps:**
    ```bash
    # 1. Invoke DR automation Lambda
    aws lambda invoke \
        --function-name mita-dr-automation \
        --payload '{"operation": "failover", "reason": "primary_region_failure"}' \
        --region us-east-1 \
        /tmp/response.json
    
    # 2. Monitor failover progress
    aws logs tail /aws/lambda/mita-dr-automation --follow
    
    # 3. Verify DR resources
    # Check RDS promotion status
    aws rds describe-db-instances \
        --db-instance-identifier mita-postgresql-dr \
        --region us-west-2
    
    # Check Redis availability
    aws elasticache describe-replication-groups \
        --replication-group-id mita-redis-dr \
        --region us-west-2
    
    # 4. Update DNS records (if not automated)
    # Point api.mita.finance to DR region load balancer
    
    # 5. Deploy application to DR region EKS cluster
    kubectl config use-context mita-dr-cluster
    helm upgrade mita ./k8s/mita \
        --set database.host=<DR_RDS_ENDPOINT> \
        --set redis.host=<DR_REDIS_ENDPOINT>
    
    # 6. Verify application functionality
    curl -k https://api.mita.finance/health
    ```
    
    ### 2. Database Failure Only
    **Triggers:**
    - Primary RDS instance failure
    - Database corruption
    - Performance degradation
    
    **Response Steps:**
    ```bash
    # 1. Promote read replica in DR region
    aws rds promote-read-replica \
        --db-instance-identifier mita-postgresql-dr \
        --region us-west-2
    
    # 2. Update application database configuration
    kubectl patch secret mita-database-config \
        -p '{"data":{"host":"<BASE64_ENCODED_DR_ENDPOINT>"}}'
    
    # 3. Restart application pods
    kubectl rollout restart deployment/mita
    
    # 4. Monitor application health
    kubectl get pods -l app=mita
    ```
    
    ### 3. Cache System Failure
    **Triggers:**
    - Redis cluster failure
    - Performance issues
    - Data corruption
    
    **Response Steps:**
    ```bash
    # 1. Verify DR Redis cluster status
    aws elasticache describe-replication-groups \
        --replication-group-id mita-redis-dr \
        --region us-west-2
    
    # 2. Update application Redis configuration
    kubectl patch secret mita-redis-config \
        -p '{"data":{"host":"<BASE64_ENCODED_DR_ENDPOINT>"}}'
    
    # 3. Clear application cache and restart
    kubectl exec -it deployment/mita -- python manage.py clear_cache
    kubectl rollout restart deployment/mita
    ```
    
    ## Recovery Procedures
    
    ### Returning from DR to Primary Region
    **Prerequisites:**
    - Primary region services restored
    - Data synchronization verified
    - Application testing completed
    
    **Steps:**
    ```bash
    # 1. Create final backup in DR region
    aws rds create-db-snapshot \
        --db-instance-identifier mita-postgresql-dr \
        --db-snapshot-identifier mita-dr-final-backup-$(date +%Y%m%d%H%M%S) \
        --region us-west-2
    
    # 2. Restore database to primary region
    aws rds restore-db-instance-from-db-snapshot \
        --db-instance-identifier mita-postgresql-restored \
        --db-snapshot-identifier mita-dr-final-backup-<TIMESTAMP> \
        --region us-east-1
    
    # 3. Set up new read replica in DR region
    aws rds create-db-instance-read-replica \
        --db-instance-identifier mita-postgresql-dr-new \
        --source-db-instance-identifier mita-postgresql-restored \
        --region us-west-2
    
    # 4. Update application configuration
    kubectl config use-context mita-primary-cluster
    helm upgrade mita ./k8s/mita \
        --set database.host=<PRIMARY_RDS_ENDPOINT> \
        --set redis.host=<PRIMARY_REDIS_ENDPOINT>
    
    # 5. Update DNS records
    # Point api.mita.finance back to primary region
    
    # 6. Monitor application health
    curl -k https://api.mita.finance/health
    ```
    
    ## Testing Procedures
    
    ### Monthly DR Test
    ```bash
    # 1. Schedule maintenance window
    # 2. Run automated DR test
    aws lambda invoke \
        --function-name mita-dr-automation \
        --payload '{"operation": "test", "test_type": "full"}' \
        /tmp/test-response.json
    
    # 3. Review test results
    cat /tmp/test-response.json | jq '.'
    
    # 4. Document any issues found
    # 5. Update procedures if needed
    ```
    
    ### Quarterly Failover Simulation
    ```bash
    # 1. Notify stakeholders of planned test
    # 2. Perform controlled failover during maintenance window
    # 3. Verify all systems in DR region
    # 4. Practice recovery procedures
    # 5. Document lessons learned
    ```
    
    ## Monitoring and Alerts
    
    ### Key Metrics to Monitor
    - Primary region health checks
    - Database replication lag
    - Cross-region backup status
    - DR infrastructure health
    - Network connectivity between regions
    
    ### Critical Alerts
    - Primary region failure detection
    - RDS replication lag > 15 minutes
    - DR infrastructure component failures
    - Backup verification failures
    
    ## Contact Information
    
    ### Emergency Contacts
    - **DevOps Team Lead:** [On-call rotation]
    - **Database Administrator:** [24/7 support]
    - **Application Team Lead:** [Business hours]
    - **Security Team:** [Critical issues only]
    
    ### Escalation Procedures
    1. **Level 1:** DevOps engineer attempts automated recovery
    2. **Level 2:** Senior DevOps and DBA engaged
    3. **Level 3:** Management and vendor support engaged
    4. **Level 4:** CEO and board notification for extended outages
    
    ## Compliance and Documentation
    
    ### Required Documentation
    - Pre-incident system state
    - Timeline of actions taken
    - Root cause analysis
    - Lessons learned
    - Preventive measures implemented
    
    ### Regulatory Requirements
    - PCI-DSS incident reporting
    - SOX compliance documentation
    - Customer notification procedures
    - Audit trail maintenance
    
    ## Recovery Validation Checklist
    
    ### Technical Validation
    - [ ] Database connectivity restored
    - [ ] Cache system operational
    - [ ] Application health checks passing
    - [ ] API endpoints responding
    - [ ] File storage accessible
    - [ ] Monitoring systems active
    
    ### Business Validation
    - [ ] User authentication working
    - [ ] Transaction processing functional
    - [ ] Reporting systems operational
    - [ ] Backup processes running
    - [ ] Security controls active
    - [ ] Audit logging enabled
    
    ### Performance Validation
    - [ ] Response times within SLA
    - [ ] Database performance acceptable
    - [ ] Cache hit rates normal
    - [ ] Resource utilization optimal
    - [ ] Error rates minimal
    
    ---
    
    **Document Version:** 1.0
    **Last Updated:** $(date)
    **Review Frequency:** Quarterly
    **Next Review Date:** $(date -d "+3 months")